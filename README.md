# sentinel
Intelligent moderation and analysis service â€” powered by local LLM inference (Ollama + Phi-4-mini-instruct).
